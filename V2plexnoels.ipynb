{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_spherical_function(k, d):\n",
    "    x, y, z = d[..., 0:1], d[..., 1:2], d[..., 2:3]\n",
    "\n",
    "    # Modified from https://github.com/google/spherical-harmonics/blob/master/sh/spherical_harmonics.cc\n",
    "    return 0.282095 * k[..., 0] + \\\n",
    "        - 0.488603 * y * k[..., 1] + 0.488603 * z * k[..., 2] - 0.488603 * x * k[..., 3] + \\\n",
    "        (1.092548 * x * y * k[..., 4] - 1.092548 * y * z * k[..., 5] + 0.315392 * (2.0 * z * z - x * x - y * y) * k[\n",
    "               ..., 6] + -1.092548 * x * z * k[..., 7] + 0.546274 * (x * x - y * y) * k[..., 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NerfModel(nn.Module):\n",
    "    def __init__(self, N=256, scale=1.5):\n",
    "        \"\"\"\n",
    "        :param N\n",
    "        :param scale: The maximum absolute value among all coordinates for objects in the scene\n",
    "        \"\"\"\n",
    "        super(NerfModel, self).__init__()\n",
    "\n",
    "        self.voxel_grid = nn.Parameter(torch.ones((N, N, N, 27 + 1)) / 100)\n",
    "        self.scale = scale\n",
    "        self.N = N\n",
    "\n",
    "    def forward(self, x, d):\n",
    "        color = torch.zeros_like(x)\n",
    "        sigma = torch.zeros((x.shape[0]), device=x.device)\n",
    "        mask = (x[:, 0].abs() < self.scale) & (x[:, 1].abs() < self.scale) & (x[:, 2].abs() < self.scale)\n",
    "\n",
    "        idx = (x[mask] / (2 * self.scale / self.N) + self.N / 2).long().clip(0, self.N - 1)\n",
    "        tmp = self.voxel_grid[idx[:, 0], idx[:, 1], idx[:, 2]]\n",
    "        sigma[mask], k = torch.nn.functional.relu(tmp[:, 0]), tmp[:, 1:]\n",
    "        color[mask] = eval_spherical_function(k.reshape(-1, 3, 9), d[mask])\n",
    "        return color, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(hn, hf, dataset, chunk_size=10, img_index=0, nb_bins=250, H=400, W=400):\n",
    "    ray_origins = dataset[img_index * H * W: (img_index + 1) * H * W, :3]\n",
    "    ray_directions = dataset[img_index * H * W: (img_index + 1) * H * W, 3:6]\n",
    "\n",
    "    data = []\n",
    "    for i in range(int(np.ceil(H / chunk_size))):\n",
    "        ray_origins_ = ray_origins[i * W * chunk_size: (i + 1) * W * chunk_size].to(device)\n",
    "        ray_directions_ = ray_directions[i * W * chunk_size: (i + 1) * W * chunk_size].to(device)\n",
    "        regenerated_px_values = render_rays(model, ray_origins_, ray_directions_, hn=hn, hf=hf, nb_bins=nb_bins)\n",
    "        data.append(regenerated_px_values)\n",
    "    img = torch.cat(data).data.cpu().numpy().reshape(H, W, 3)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.savefig(f'Imgs/img_{img_index}d.png', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accumulated_transmittance(alphas):\n",
    "    accumulated_transmittance = torch.cumprod(alphas, 1)\n",
    "    return torch.cat((torch.ones((accumulated_transmittance.shape[0], 1), device=alphas.device),\n",
    "                      accumulated_transmittance[:, :-1]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_rays(nerf_model, ray_origins, ray_directions, hn=0, hf=0.5, nb_bins=250):\n",
    "    device = ray_origins.device\n",
    "    t = torch.linspace(hn, hf, nb_bins, device=device).expand(ray_origins.shape[0], nb_bins)\n",
    "    # Perturb sampling along each ray.\n",
    "    mid = (t[:, :-1] + t[:, 1:]) / 2.\n",
    "    lower = torch.cat((t[:, :1], mid), -1)\n",
    "    upper = torch.cat((mid, t[:, -1:]), -1)\n",
    "    u = torch.rand(t.shape, device=device)\n",
    "    t = lower + (upper - lower) * u  # [batch_size, nb_bins]\n",
    "    delta = torch.cat((t[:, 1:] - t[:, :-1], torch.tensor([1e10], device=device).expand(ray_origins.shape[0], 1)), -1)\n",
    "\n",
    "    x = ray_origins.unsqueeze(1) + t.unsqueeze(2) * ray_directions.unsqueeze(1)  # [batch_size, nb_bins, 3]\n",
    "    ray_directions = ray_directions.expand(nb_bins, ray_directions.shape[0], 3).transpose(0, 1)\n",
    "\n",
    "    colors, sigma = nerf_model(x.reshape(-1, 3), ray_directions.reshape(-1, 3))\n",
    "    colors = colors.reshape(x.shape)\n",
    "    sigma = sigma.reshape(x.shape[:-1])\n",
    "\n",
    "    alpha = 1 - torch.exp(-sigma * delta)  # [batch_size, nb_bins]\n",
    "    weights = compute_accumulated_transmittance(1 - alpha).unsqueeze(2) * alpha.unsqueeze(2)\n",
    "    c = (weights * colors).sum(dim=1)  # Pixel values\n",
    "    weight_sum = weights.sum(-1).sum(-1)  # Regularization for white background\n",
    "    return c + 1 - weight_sum.unsqueeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(nerf_model, optimizer, scheduler, data_loader, device='cpu', hn=0, hf=1, nb_epochs=int(1e6),\n",
    "          nb_bins=250):\n",
    "    training_loss = []\n",
    "    for _ in range(nb_epochs):\n",
    "        for batch in tqdm(data_loader):\n",
    "            ray_origins = batch[:, :3].to(device)\n",
    "            ray_directions = batch[:, 3:6].to(device)\n",
    "            ground_truth_px_values = batch[:, 6:].to(device)\n",
    "\n",
    "            regenerated_px_values = render_rays(nerf_model, ray_origins, ray_directions, hn=hn, hf=hf, nb_bins=nb_bins)\n",
    "            loss = torch.nn.functional.mse_loss(ground_truth_px_values, regenerated_px_values)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss.append(loss.item())\n",
    "\n",
    "        scheduler.step()\n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_voxel_grid(model, filepath=\"voxel_grid.csv\"):\n",
    "    \"\"\"\n",
    "    Exports the voxel grid to a CSV file.\n",
    "    \n",
    "    :param model: The trained NerfModel instance.\n",
    "    :param filepath: Path to the output CSV file.\n",
    "    \"\"\"\n",
    "    with open(filepath, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['x', 'y', 'z', 'sigma', 'r', 'g', 'b'])\n",
    "\n",
    "        voxel_grid = model.voxel_grid.detach().cpu().numpy()  # Ensure it's on CPU and converted to numpy\n",
    "        N = model.N  # Resolution of the voxel grid\n",
    "        scale = model.scale  # Scale of the model\n",
    "\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                for k in range(N):\n",
    "                    # Compute normalized coordinates [-scale, scale]\n",
    "                    x = (i / N) * 2 * scale - scale\n",
    "                    y = (j / N) * 2 * scale - scale\n",
    "                    z = (k / N) * 2 * scale - scale\n",
    "                    \n",
    "                    voxel = voxel_grid[i, j, k]\n",
    "                    sigma = voxel[0]  # Density or sigma value\n",
    "                    color = voxel[1:4]  # RGB color\n",
    "                    \n",
    "                    # Write voxel data to CSV\n",
    "                    writer.writerow([x, y, z, sigma, *color])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13334/13334 [49:54<00:00,  4.45it/s]    \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = 'cuda'\n",
    "    training_dataset = torch.from_numpy(np.load('training_data.pkl', allow_pickle=True))\n",
    "    testing_dataset = torch.from_numpy(np.load('testing_data.pkl', allow_pickle=True))\n",
    "    model = NerfModel(N=169).to(device)\n",
    "    model_optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(model_optimizer, milestones=[2, 4, 8], gamma=0.5)\n",
    "\n",
    "    data_loader = DataLoader(training_dataset, batch_size=1200, shuffle=True)\n",
    "    train(model, model_optimizer, scheduler, data_loader, nb_epochs=1, device=device, hn=2, hf=6, nb_bins=250)\n",
    "    for img_index in [0, 30, 45, 60, 75, 90, 105, 120, 135, 150, 169, 180]:\n",
    "        test(2, 6, testing_dataset, img_index=img_index, nb_bins=256, H=400, W=400)\n",
    "    export_voxel_grid(model, filepath=\"output_voxel_grid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#train(model, model_optimizer, scheduler, data_loader, nb_epochs=1, device=device, hn=2, hf=6, nb_bins=250)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m6\u001b[39m, testing_dataset, img_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m129\u001b[39m, nb_bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, H\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m, W\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "#train(model, model_optimizer, scheduler, data_loader, nb_epochs=1, device=device, hn=2, hf=6, nb_bins=250)\n",
    "test(2,6, testing_dataset, img_index=129, nb_bins=64, H=400, W=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test2(hn, hf, dataset, chunk_size=10, img_index=0, nb_bins=64, H=400, W=400):\n",
    "    ray_origins = dataset[img_index * H * W: (img_index + 1) * H * W, :3]\n",
    "    ray_directions = dataset[img_index * H * W: (img_index + 1) * H * W, 3:6]\n",
    "\n",
    "    data = []\n",
    "    for i in range(int(np.ceil(H / chunk_size))):\n",
    "        ray_origins_ = ray_origins[i * W * chunk_size: (i + 1) * W * chunk_size].to(device)\n",
    "        ray_directions_ = ray_directions[i * W * chunk_size: (i + 1) * W * chunk_size].to(device)\n",
    "        regenerated_px_values = render_rays(model, ray_origins_, ray_directions_, hn=hn, hf=hf, nb_bins=nb_bins)\n",
    "        data.append(regenerated_px_values)\n",
    "    img = torch.cat(data).data.cpu().numpy().reshape(H, W, 3)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.savefig(f'ImgTesting/img_{img_index}.png', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_voxel_grid(model, filepath=\"testalphabeta.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
